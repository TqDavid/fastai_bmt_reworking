{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5110)\n"
     ]
    }
   ],
   "source": [
    "from theano.sandbox import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#set FIXED variables\n",
    "HOMEPATH = \"/home/ubuntu/fastai/\"\n",
    "MODELPATH = HOMEPATH + 'dogscats/models/'\n",
    "TRAINPATH = HOMEPATH + 'dogscats/train/'\n",
    "VALIDPATH = HOMEPATH + 'dogscats/valid/'\n",
    "MODELPATH = HOMEPATH + 'dogscats/models/'\n",
    "TESTPATH = HOMEPATH + 'dogscats/test1/'\n",
    "import os\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/fastai\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "os.chdir(HOMEPATH)\n",
    "print (os.getcwd())\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from __future__ import division, print_function\n",
    "#NB: lecture shows as using Theano backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "#import os#already imported\n",
    "\n",
    "def set_keras_backend(backend):\n",
    "\n",
    "    if K.backend() != backend:\n",
    "        os.environ['KERAS_BACKEND'] = backend\n",
    "        reload(K)\n",
    "        assert K.backend() == backend\n",
    "\n",
    "set_keras_backend(\"theano\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#this is redundant since already generated this dir\n",
    "if not os.path.exists(MODELPATH): os.mkdir(MODELPATH)\n",
    "\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg_ft(2)\n",
    "#uses def vgg_ft(out_dim): from utils.py\n",
    "#creates Vgg16 object &  calls Vgg16.ft(self, num) method\n",
    "#Replace the last layer of the model with a Dense (fully connected) layer of 2 neurons.\n",
    "#also lock the weights of all layers except the new layer so that we only learn\n",
    "#weights for the last layer in subsequent training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.models.Sequential"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    }
   ],
   "source": [
    "print(len(model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(MODELPATH+'finetune3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'> 38\n"
     ]
    }
   ],
   "source": [
    "layers = model.layers\n",
    "print (type(layers), len(layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_conv_idx = [index for index,layer in enumerate(layers) \n",
    "                     if type(layer) is Convolution2D][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_conv_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.convolutional.Convolution2D at 0x7fb9b71bf690>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers[last_conv_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layers = layers[:last_conv_idx+1]  #all layers up to the last convolutional layer\n",
    "#NB: none of the convolutional layers in vgg16 have dropout\n",
    "\n",
    "conv_model = Sequential(conv_layers)\n",
    "# Dense layers - also known as fully connected or 'FC' layers\n",
    "fc_layers = layers[last_conv_idx+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.models.Sequential'>\n",
      "<class 'keras.models.Sequential'>\n"
     ]
    }
   ],
   "source": [
    "print (type(conv_model))\n",
    "print (type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'> 31 <class 'keras.layers.core.Lambda'>\n",
      "<class 'keras.models.Sequential'>\n",
      "<type 'list'> 7 <class 'keras.layers.pooling.MaxPooling2D'>\n",
      "0 <class 'keras.layers.core.Lambda'>\n",
      "1 <class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "2 <class 'keras.layers.convolutional.Convolution2D'>\n",
      "3 <class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "4 <class 'keras.layers.convolutional.Convolution2D'>\n",
      "5 <class 'keras.layers.pooling.MaxPooling2D'>\n",
      "6 <class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "7 <class 'keras.layers.convolutional.Convolution2D'>\n",
      "8 <class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "9 <class 'keras.layers.convolutional.Convolution2D'>\n",
      "10 <class 'keras.layers.pooling.MaxPooling2D'>\n",
      "11 <class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "12 <class 'keras.layers.convolutional.Convolution2D'>\n",
      "13 <class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "14 <class 'keras.layers.convolutional.Convolution2D'>\n",
      "15 <class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "16 <class 'keras.layers.convolutional.Convolution2D'>\n",
      "17 <class 'keras.layers.pooling.MaxPooling2D'>\n",
      "18 <class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "19 <class 'keras.layers.convolutional.Convolution2D'>\n",
      "20 <class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "21 <class 'keras.layers.convolutional.Convolution2D'>\n",
      "22 <class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "23 <class 'keras.layers.convolutional.Convolution2D'>\n",
      "24 <class 'keras.layers.pooling.MaxPooling2D'>\n",
      "25 <class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "26 <class 'keras.layers.convolutional.Convolution2D'>\n",
      "27 <class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "28 <class 'keras.layers.convolutional.Convolution2D'>\n",
      "29 <class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "30 <class 'keras.layers.convolutional.Convolution2D'>\n"
     ]
    }
   ],
   "source": [
    "print (type(conv_layers), len(conv_layers), type(conv_layers[0]))\n",
    "print (type(conv_model))\n",
    "print (type(fc_layers), len(fc_layers), type(fc_layers[0]))\n",
    "i=0\n",
    "for layer in conv_layers:\n",
    "    print (i, type(layer))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = get_batches(TRAINPATH, shuffle=False, batch_size=batch_size)\n",
    "val_batches = get_batches(VALIDPATH, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "val_classes = val_batches.classes\n",
    "trn_classes = batches.classes\n",
    "val_labels = onehot(val_classes)\n",
    "trn_labels = onehot(trn_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime= datetime.now()\n",
    "val_features = conv_model.predict_generator(val_batches, val_batches.nb_sample)\n",
    "timeElapsed=datetime.now()-startTime\n",
    "print('Time elpased (hh:mm:ss.ms) {}'.format(timeElapsed))\n",
    "\n",
    "print (type(val_features), val_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime= datetime.now()\n",
    "trn_features = conv_model.predict_generator(batches, batches.nb_sample)\n",
    "timeElapsed=datetime.now()-startTime\n",
    "print('Time elpased (hh:mm:ss.ms) {}'.format(timeElapsed))\n",
    "\n",
    "print (type(trn_features), trn_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_array(MODELPATH + 'train_convlayer_features.bc', trn_features)\n",
    "save_array(MODELPATH + 'valid_convlayer_features.bc', val_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"trn_features:\", type(trn_features), trn_features.shape)\n",
    "print (\"val_features:\", type(val_features), val_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_features = load_array(MODELPATH+'train_convlayer_features.bc')\n",
    "val_features = load_array(MODELPATH+'valid_convlayer_features.bc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the weights from the pre-trained model.\n",
    "# NB: Since we're removing dropout, we want to half the weights\n",
    "# NBB: previously dropout was 0.5, so with no dropout we need to mult weights by 1/2\n",
    "def proc_wgts(layer): \n",
    "    return [o/2 for o in layer.get_weights()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Such a finely tuned model needs to be updated very slowly!\n",
    "opt = RMSprop(lr=0.00001, rho=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fc_model():\n",
    "    model = Sequential([\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.),\n",
    "        Dense(2, activation='softmax')\n",
    "        ])\n",
    "\n",
    "    for l1,l2 in zip(model.layers, fc_layers): \n",
    "        l1.set_weights(proc_wgts(l2))\n",
    "\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_model = get_fc_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(fc_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime= datetime.now()\n",
    "fc_model.fit(trn_features, trn_labels, nb_epoch=8, \n",
    "             batch_size=batch_size, validation_data=(val_features, val_labels))\n",
    "timeElapsed=datetime.now()-startTime\n",
    "print('Time elpased (hh:mm:ss.ms) {}'.format(timeElapsed))\n",
    "\n",
    "#nb: accuracy on training is higher than accuracy on validation. _OVERFITTING_\n",
    "#week 3 video @ 1hr26'\n",
    "\n",
    "#best accuracy training: 0.9909, validation: 0.9840"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fc_model.save_weights(MODELPATH+'no_dropout.h5')#already saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fc_model.load_weights(MODELPATH+'no_dropout.h5')#already have values in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augmentation\n",
    "\n",
    "# dim_ordering='tf' uses tensorflow dimension ordering,\n",
    "#   which is the same order as matplotlib uses for display.\n",
    "# Therefore when just using for display purposes, this is more convenient\n",
    "gen = image.ImageDataGenerator(rotation_range=10, width_shift_range=0.1, \n",
    "       height_shift_range=0.1, shear_range=0.15, zoom_range=0.1, \n",
    "       channel_shift_range=10., horizontal_flip=True, dim_ordering='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 'batch' of a single image\n",
    "img = np.expand_dims(ndimage.imread(HOMEPATH+'dogscats/test1/7.jpg'),0)\n",
    "# Request the generator to create batches from this image\n",
    "aug_iter = gen.flow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = ndimage.imread(HOMEPATH+'dogscats/test1/7.jpg')\n",
    "print (type(temp), temp.shape)\n",
    "print (type(img), img.shape)\n",
    "print (type(aug_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get eight examples of these augmented images\n",
    "aug_imgs = [next(aug_iter)[0].astype(np.uint8) for i in range(8)]\n",
    "print (type(aug_imgs), len(aug_imgs), type(aug_imgs[0]), aug_imgs[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The original\n",
    "plt.imshow(img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmented data\n",
    "plots(aug_imgs, (20,7), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that we return to theano dimension ordering\n",
    "K.set_image_dim_ordering('th')\n",
    "print (type(K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding augmentation\n",
    "gen = image.ImageDataGenerator(rotation_range=15, \n",
    "                               width_shift_range=0.1, \n",
    "                               height_shift_range=0.1, \n",
    "                               zoom_range=0.1, \n",
    "                               horizontal_flip=True)\n",
    "print (type(gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = get_batches(TRAINPATH, gen, batch_size=batch_size)\n",
    "\n",
    "#from vgg16.py\n",
    "#def get_batches(self, path, gen=image.ImageDataGenerator(), shuffle=True, batch_size=8, class_mode='categorical'):\n",
    "# NB: We don't want to augment or shuffle the validation set\n",
    "\n",
    "val_batches = get_batches(VALIDPATH, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "#NB: output reports the same number of images belonging to same number of classes as when \n",
    "#keras.preprocessing.image.ImageDataGenerator was not used.\n",
    "\n",
    "print (\"batches:\", type(batches))\n",
    "print (\"val_batches:\", type(val_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(conv_model.layers))\n",
    "fc_model = get_fc_model()\n",
    "print(len(fc_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set convolutions models to non trainable\n",
    "for layer in conv_model.layers: \n",
    "    layer.trainable = False\n",
    "# Look how easy it is to connect two models together!\n",
    "conv_model.add(fc_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(conv_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the layers\n",
    "i=0\n",
    "for layer in conv_model.layers:\n",
    "    print (i, type(layer))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime= datetime.now()\n",
    "conv_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "timeElapsed=datetime.now()-startTime\n",
    "print('Time elpased (hh:mm:ss.ms) {}'.format(timeElapsed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime= datetime.now()\n",
    "conv_model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=8, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "timeElapsed=datetime.now()-startTime\n",
    "print('Time elpased (hh:mm:ss.ms) {}'.format(timeElapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary from above\n",
    "#best training accuracy   :0.9833\n",
    "#best validation accuracy :0.9810\n",
    "\n",
    "#identical - diff number of epochs\n",
    "#this takes a long time to run.\n",
    "print (\"start\")\n",
    "startTime= datetime.now()\n",
    "conv_model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=3, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "timeElapsed=datetime.now()-startTime\n",
    "print('Time elpased (hh:mm:ss.ms) {}'.format(timeElapsed))\n",
    "\n",
    "#summary for this block\n",
    "#best training accuracy   :0.9852\n",
    "#best validation accuracy :0.9820\n",
    "#if training accuracy > validation accuracy then overfitting (maybe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model.save_weights(MODELPATH + 'aug1.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conv_model.load_weights(MODELPATH + 'aug1.h5') #model already loaded.\n",
    "#print (\"model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Batch normalization (batchnorm) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (type(conv_layers), len(conv_layers), type(conv_layers[0]))\n",
    "print (\"last layer :\", type(conv_layers[-1]))\n",
    "print (conv_layers[-1].output_shape[1:])\n",
    "\n",
    "i=0\n",
    "for layer in conv_layers:\n",
    "    print (i, layer.output_shape[1:])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bn_layers(p):\n",
    "    '''\n",
    "    creates layers with sequence of layers as coded.\n",
    "    dropout rate as specified\n",
    "    '''\n",
    "    return [\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(4096, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(1000, activation='softmax')\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fc_weights_from_vgg16bn(model):\n",
    "    \"Load weights for model from the dense layers of the Vgg16BN model.\"\n",
    "    # See imagenet_batchnorm.ipynb for info on how the weights for\n",
    "    # Vgg16BN can be generated from the standard Vgg16 weights.\n",
    "    from vgg16bn import Vgg16BN\n",
    "    vgg16_bn = Vgg16BN()\n",
    "    _, fc_layers = split_at(vgg16_bn.model, Convolution2D)\n",
    "    copy_weights(fc_layers, model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = get_bn_layers(0.6)\n",
    "print (type(temp), len(temp), type(temp[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_model = Sequential(get_bn_layers(0.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (type(bn_model), len(bn_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_fc_weights_from_vgg16bn(bn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_wgts(layer, prev_p, new_p):\n",
    "    scal = (1-prev_p)/(1-new_p)\n",
    "    return [o*scal for o in layer.get_weights()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = proc_wgts(l, 0.5, 0.6)\n",
    "print (type(temp), len(temp))\n",
    "print (type(temp[0]), type(temp[1]))\n",
    "print (temp[0].shape, temp[1].shape)\n",
    "print ((1-0.5)/(1-0.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each layer in bn_model.layers\n",
    "#set weights ine ach layer to a scalar mult of existing weights.\n",
    "#avoid running this multiple times!!!!\n",
    "\n",
    "for l in bn_model.layers: \n",
    "    if type(l)==Dense: l.set_weights(proc_wgts(l, 0.5, 0.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (type(bn_model), type(bn_model.layers), len(bn_model.layers))\n",
    "i=0\n",
    "for layer in bn_model.layers:\n",
    "    print (i, type(layer), layer.output_shape[1:])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_model.pop()\n",
    "#remove last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (type(bn_model), type(bn_model.layers), len(bn_model.layers))\n",
    "\n",
    "i=0\n",
    "for layer in bn_model.layers:\n",
    "    print (i, type(layer), layer.trainable, layer.output_shape[1:])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set all layers to non trainable\n",
    "for layer in bn_model.layers: \n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add Dense layer back - we deleted Dense layer during \"bn_model.pop()\"\n",
    "bn_model.add(Dense(2,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for layer in bn_model.layers:\n",
    "    print (i, type(layer), layer.trainable, layer.output_shape[1:])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(bn_model)\n",
    "#https://keras.io/models/sequential/\n",
    "#compile(self, optimizer, loss, metrics=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None)\n",
    "#https://keras.io/optimizers/\n",
    "#Adam - A method for stochastic optimisation : https://arxiv.org/abs/1412.6980v8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"start\")\n",
    "startTime= datetime.now()\n",
    "bn_model.compile(Adam(), 'categorical_crossentropy', metrics=['accuracy'])\n",
    "timeElapsed=datetime.now()-startTime\n",
    "print('Time elpased (hh:mm:ss.ms) {}'.format(timeElapsed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"start\")\n",
    "startTime= datetime.now()\n",
    "bn_model.fit(trn_features, trn_labels, nb_epoch=8, validation_data=(val_features, val_labels))\n",
    "timeElapsed=datetime.now()-startTime\n",
    "print('Time elpased (hh:mm:ss.ms) {}'.format(timeElapsed))\n",
    "#this will be fast since only retraining last layer\n",
    "#accuracy: training:0.9658 validation:0.9800 not overtrained, accuracy could be higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_model.save_weights(MODELPATH+'bn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bn_model.load_weights(model_path+'bn.h5')#value already in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_layers = get_bn_layers(0.6)\n",
    "print (type(bn_layers), len(bn_layers), type(bn_layers[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_layers.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check # of layers after pop\n",
    "print (type(bn_layers), len(bn_layers), type(bn_layers[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace last layer just deleted. same specs as previous layer added.\n",
    "bn_layers.append(Dense(2,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check # of layers after adding layer\n",
    "print (type(bn_layers), len(bn_layers), type(bn_layers[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = Sequential(conv_layers)\n",
    "print (type(final_model), type(final_model.layers), len(final_model.layers), type(final_model.layers[0]))\n",
    "\n",
    "for layer in final_model.layers: \n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in bn_layers: \n",
    "    final_model.add(layer)\n",
    "\n",
    "print (type(final_model), type(final_model.layers), len(final_model.layers), type(final_model.layers[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (type(final_model), type(final_model.layers), len(final_model.layers), type(final_model.layers[0]))\n",
    "#temp cell to show 31+9=40 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(bn_model.layers))\n",
    "print(type(bn_layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#why are we copying weights from bn_layers to bn_model.layers?\n",
    "for l1,l2 in zip(bn_model.layers, bn_layers):\n",
    "    l2.set_weights(l1.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime= datetime.now()\n",
    "final_model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=1, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "timeElapsed=datetime.now()-startTime\n",
    "print('Time elpased (hh:mm:ss.ms) {}'.format(timeElapsed))\n",
    "#accuracy - train:0.9928  validation:0.9710  - slight overtraining. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.save_weights(MODELPATH + 'final1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime= datetime.now()\n",
    "final_model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=4, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "timeElapsed=datetime.now()-startTime\n",
    "print('Time elpased (hh:mm:ss.ms) {}'.format(timeElapsed))\n",
    "#accuracy: training:0.9657 validation:0.9810"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.save_weights(MODELPATH + 'final2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.optimizer.lr=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime= datetime.now()\n",
    "final_model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=4, \n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "timeElapsed=datetime.now()-startTime\n",
    "print('Time elpased (hh:mm:ss.ms) {}'.format(timeElapsed))\n",
    "#accuracy : train:0.9673    validation:0.9795"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_model.save_weights(MODELPATH + 'final3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (type(bn_model))\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"vgg.test start\")\n",
    "batches, preds = bn_model.predict_classes(TESTPATH, batch_size = batch_size*2)\n",
    "print(\"type(batches):\", type(batches))\n",
    "print(\"type(preds):\", type(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = Vgg16()\n",
    "print (type(vgg))\n",
    "type(vgg.model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
