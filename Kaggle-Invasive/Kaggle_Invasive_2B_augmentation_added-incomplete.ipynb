{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/c/invasive-species-monitoring/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "HOMEPATH = \"/home/ubuntu/fastai/\"\n",
    "DATA_HOME_DIR = HOMEPATH + \"data/invasive/\"\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('os.getcwd:', '/home/ubuntu/fastai')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5110)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "os.chdir(HOMEPATH)\n",
    "print (\"os.getcwd:\", os.getcwd())\n",
    "# Rather than importing everything manually, we'll make things easy\n",
    "#   and load them all in utils.py, and just import them from there.\n",
    "import utils;\n",
    "from utils import *\n",
    "from shutil import copyfile\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN  = DATA_HOME_DIR + \"train/\"\n",
    "VALID  = DATA_HOME_DIR + \"valid/\"\n",
    "TEST   = DATA_HOME_DIR + \"test/\"\n",
    "RESULTS = DATA_HOME_DIR + \"results/\"\n",
    "SAMPLE =  DATA_HOME_DIR + \"sample/\"\n",
    "SAMPLE_TRAIN = SAMPLE + \"train/\"\n",
    "SAMPLE_VALID = SAMPLE + \"valid/\"\n",
    "SAMPLE_TEST = SAMPLE + \"test/\"\n",
    "SAMPLE_RESULTS = SAMPLE + \"results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('WORKING_DATA:', '/home/ubuntu/fastai/data/invasive/')\n",
      "('WORKING_TEST:', '/home/ubuntu/fastai/data/invasive/test/')\n",
      "('WORKING_TRAIN:', '/home/ubuntu/fastai/data/invasive/train/')\n",
      "('WORKING_VALID:', '/home/ubuntu/fastai/data/invasive/valid/')\n",
      "('WORKING_RESULTS:', '/home/ubuntu/fastai/data/invasive/results/')\n"
     ]
    }
   ],
   "source": [
    "#change this as appropriate between smaller sample data set(SAMPLE) and production data(DATA_HOME_DIR)\n",
    "WORKING_DATA = SAMPLE\n",
    "#WORKING_DATA = DATA_HOME_DIR \n",
    "#------------------future me : swap between above options. do not change below--------------\n",
    "WORKING_TEST = WORKING_DATA + \"test/\" #We use all the test data\n",
    "WORKING_TRAIN = WORKING_DATA + \"train/\"\n",
    "WORKING_VALID = WORKING_DATA + \"valid/\"\n",
    "WORKING_RESULTS = WORKING_DATA + \"results/\"\n",
    "\n",
    "print (\"WORKING_DATA:\", WORKING_DATA)\n",
    "print (\"WORKING_TEST:\", WORKING_TEST)\n",
    "print (\"WORKING_TRAIN:\", WORKING_TRAIN)\n",
    "print (\"WORKING_VALID:\", WORKING_VALID)\n",
    "print (\"WORKING_RESULTS:\", WORKING_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/fastai/data/invasive/\n",
      "------  6\n",
      "------ valid 0\n",
      "------- invasive 434\n",
      "------- harmless 254\n",
      "------ results 0\n",
      "------ train 0\n",
      "------- invasive 1014\n",
      "------- harmless 593\n",
      "------ test 0\n",
      "------- unknown 1531\n",
      "------ sample 0\n",
      "------- valid 0\n",
      "-------- invasive 86\n",
      "-------- harmless 50\n",
      "------- results 1\n",
      "------- train 0\n",
      "-------- invasive 202\n",
      "-------- harmless 118\n",
      "------- test 0\n",
      "-------- unknown 306\n"
     ]
    }
   ],
   "source": [
    "# traverse root directory, and list directories as dirs and files as files\n",
    "print (DATA_HOME_DIR)\n",
    "for root, dirs, files in os.walk(DATA_HOME_DIR):\n",
    "    path = root.split(os.sep)\n",
    "    print (len(path) - 1) * '-', os.path.basename(root), len(files) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate standard Vgg16 model\n",
    "from vgg16 import Vgg16\n",
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1607 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#finetune model with our data\n",
    "batches = vgg.get_batches(WORKING_TRAIN)\n",
    "vgg.finetune(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set attributes\n",
    "num_epochs = 4\n",
    "lr = 0.001\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('startTime:', datetime.datetime(2017, 12, 12, 1, 7, 45, 315671))\n",
      "Found 1607 images belonging to 2 classes.\n",
      "Found 688 images belonging to 2 classes.\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:00.047381\n"
     ]
    }
   ],
   "source": [
    "startTime= datetime.now()\n",
    "print (\"startTime:\", startTime)\n",
    "\n",
    "train_batches = vgg.get_batches(WORKING_TRAIN)\n",
    "valid_batches = vgg.get_batches(WORKING_VALID)\n",
    "\n",
    "timeElapsed=datetime.now()-startTime\n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(timeElapsed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.preprocessing.image.DirectoryIterator"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1607/1607 [==============================] - 90s - loss: 0.4780 - acc: 0.8270 - val_loss: 0.3486 - val_acc: 0.8866\n",
      "Epoch 2/4\n",
      "1296/1607 [=======================>......] - ETA: 10s - loss: 0.4111 - acc: 0.8681"
     ]
    }
   ],
   "source": [
    "#from vgg16.py: def fit(self, batches, val_batches, nb_epoch=1)\n",
    "vgg.fit(train_batches, valid_batches, nb_epoch=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_batches, valid_preds = vgg.test(WORKING_VALID)\n",
    "print (\"valid_batches:\", type(valid_batches))\n",
    "valid_filenames = valid_batches.filenames\n",
    "expected_labels = valid_batches.classes\n",
    "print (\"valid_filenames:\", type(valid_filenames), len(valid_filenames))\n",
    "print (\"expected_labels:\", type(expected_labels), len(expected_labels))\n",
    "print \"valid_filenames\", valid_filenames[0:5]\n",
    "print \"expected_labels\", expected_labels[0:5]\n",
    "print \"valid_batches.class_indices:\", valid_batches.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick visual inspection\n",
    "valid_preds[:5]\n",
    "#col 0 = predictions of harmless, col 1 = predictions of invasive\n",
    "#nb: row sum = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_predictions = valid_preds[:,1]\n",
    "print (\"our_predictions:\", our_predictions[0:5])\n",
    "valid_pred_labels = np.round(valid_preds[:,1])\n",
    "print (\"valid_pred_labels:\", valid_pred_labels[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print valid_pred_labels.shape\n",
    "valid_pred_labels[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(expected_labels, valid_pred_labels)\n",
    "plot_confusion_matrix(cm, valid_batches.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(expected_labels, valid_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of images to view for each visualization task\n",
    "n_view = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "#Helper function to plot images by index in the validation set \n",
    "#Plots is a helper function in utils.py\n",
    "def plots_idx(idx, titles):\n",
    "    plots([image.load_img(WORKING_VALID + valid_filenames[i]) for i in idx], titles=titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFilenames(idx):\n",
    "    filenames_ = []\n",
    "    for i in idx:\n",
    "        filenames_.append(valid_filenames[i])\n",
    "    return filenames_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProbs(idx):\n",
    "    probs_ = []\n",
    "    for i in idx:\n",
    "        probs_.append(our_predictions[i])\n",
    "    return probs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotSelected(correct, description):\n",
    "    print(\"found %d %s labels\" % (len(correct), description))\n",
    "    idx = np.random.permutation(correct)\n",
    "    titles = np.where(our_labels[idx[:n_view]] == 0.0, 'harmless', 'invasive')\n",
    "    plots_idx(idx[:n_view], titles)\n",
    "    print getFilenames(idx[:n_view])\n",
    "    print getProbs(idx[:n_view])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected at random: correctly predicted labels\n",
    "correct = np.where(our_labels == expected_labels)[0]\n",
    "plotSelected(correct, \"correct\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected at random: incorrectly predicted labels\n",
    "correct = np.where(our_labels != expected_labels)[0]\n",
    "plotSelected(correct, \"incorrect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_uncertain = np.argsort(abs(our_predictions-0.5))\n",
    "plotSelected(most_uncertain[:n_view], \"most uncertain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batches, test_preds = vgg.test(WORKING_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filenames = test_batches.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.array([int(f[8:f.find('.')]) for f in test_filenames])\n",
    "ids[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_invasive = test_preds[:,1]\n",
    "print (is_invasive[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts: 41435\n"
     ]
    }
   ],
   "source": [
    "ts = str(int(time.time()))[-5:]\n",
    "print \"ts:\", ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = np.stack((ids, is_invasive), axis = 1)\n",
    "filename = WORKING_RESULTS+\"aspiringguru.csv\"\n",
    "np.savetxt(filename, submission, fmt=\"%d,%.3f\", header='name,invasive', comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
