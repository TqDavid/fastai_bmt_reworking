{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "path = \"/home/ubuntu/data2/dogscats/\"\n",
    "home = \"/home/ubuntu/\"\n",
    "#set home directory\n",
    "import os\n",
    "os.chdir(home)\n",
    "\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "print (\"loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do list- from kaggle comp instructions\n",
    "https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition\n",
    "1. create validation and sample\n",
    "2. move to separate dirs for each set\n",
    "3. finetune and train\n",
    "4. submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data2/dogscats\n"
     ]
    }
   ],
   "source": [
    "%cd data2/dogscats\n",
    "# splitting of files from test into validation already done.\n",
    "# splitting of files into categories dogs and cats already done in valid directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from vgg16 import Vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started\n",
      "Found 23000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"started\")\n",
    "batches = vgg.get_batches(path+'train', batch_size=batch_size)\n",
    "val_batches = vgg.get_batches(path+'valid', batch_size=batch_size*2)\n",
    "vgg.finetune(batches)\n",
    "print (\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Epoch 1/1\n",
      "23000/23000 [==============================] - 719s - loss: 0.1244 - acc: 0.9673 - val_loss: 0.0552 - val_acc: 0.9820\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "print(\"start\")\n",
    "vgg.fit(batches, val_batches, nb_epoch=1)\n",
    "vgg.model.save_weights('dogs-cats-results_1epoch_1.h5')\n",
    "print(\"end__\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg.model.optimizer.lr = 0.01 #refer lesson 2 video @ 38:05, might improve results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Epoch 1/1\n",
      "23000/23000 [==============================] - 722s - loss: 0.0999 - acc: 0.9757 - val_loss: 0.0694 - val_acc: 0.9845\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "#this gave Exception: output of generator should be a tuple (x, y, sample_weight) or (x, y). \n",
    "#refer lesson 2 video @ 38.09\n",
    "print(\"start\")\n",
    "vgg.fit(batches, val_batches, nb_epoch=1)\n",
    "vgg.model.save_weights('results_ft1_5epoch_2nd_run.h5')\n",
    "print(\"end\")\n",
    "#https://keras.io/models/about-keras-models/\n",
    "#model.load_weights(filepath, by_name=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#in command prompt. move files from test1 to test1/a\n",
    "#vgg.test needs files to be in one directory otherwise fails w error message zero files found & /0 error\n",
    "print (\"vgg.test start\")\n",
    "batches, preds = vgg.test(path+'test1', batch_size = batch_size*2)\n",
    "print(\"type(batches):\", type(batches))\n",
    "print(\"type(batches.filenames):\", type(batches.filenames))\n",
    "print(\"type(preds):\", type(preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#store results in file so we don't lose the results from long detailed calc.\n",
    "\n",
    "filenames = batches.filenames\n",
    "save_array(path+'test_preds.dat', preds)\n",
    "save_array(path+'filenames.dat', filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(batches.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batches.filenames[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds[0:5]\n",
    "#NB: in lecture the output is 1. and 0. not a range of non-int probs summing to 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = load_array('test_preds.dat')\n",
    "filenames = load_array('filenames.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(type(preds), preds.shape)\n",
    "print(type(filenames), filenames.shape)\n",
    "#we can see 12500 rows of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://keras.io/models/sequential/  \n",
    "predict_generator(self, generator, steps, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)  \n",
    "also refer vgg16.py  \n",
    "def test(self, path, batch_size=8)  \n",
    "return test_batches, self.model.predict_generator(test_batches, test_batches.nb_sample)  \n",
    "NB: class_mode=None  \n",
    "def get_batches(self, path, gen=image.ImageDataGenerator(), shuffle=True, batch_size=8, class_mode='categorical'):  \n",
    "class_mode='categorical'  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "#nb: jupyter notebook only displays the last output.\n",
    "#Image.open('test1/'+filenames[0])\n",
    "Image.open('test1/'+filenames[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "isdog = preds[:, 1]\n",
    "isdog[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "isdog = isdog.clip(0.05, 0.95)\n",
    "isdog[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#strip out the int's from filename and store in list.\n",
    "#ids = [f for f in filenames]\n",
    "#print(ids[:5])\n",
    "ids = [int(f[2:f.find('.')]) for f in filenames]\n",
    "ids[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subm = np.stack([ids, isdog], axis=1)\n",
    "subm[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('submit.csv', subm, fmt='%d,%.5f', header='id,label', comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Ipython.display import FileLink\n",
    "FileLink('submit.csv')\n",
    "#error. library not installed? tried pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"calc confusion matrix\")\n",
    "cm = confusion_matrix(labels, preds)\n",
    "print(\"confusion matrix created.\", type(cm))\n",
    "plot_confusion_matrix(cm, val_batches.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
