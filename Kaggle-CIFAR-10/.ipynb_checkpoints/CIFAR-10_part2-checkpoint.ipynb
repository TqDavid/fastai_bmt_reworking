{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('DATA_WORKING      :', '/home/ubuntu/fastai/data/cifar-10/sample/')\n",
      "('DATA_WORKING_RESULTS:', '/home/ubuntu/fastai/data/cifar-10/sample/results/')\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "HOMEPATH = \"/home/ubuntu/fastai/\"\n",
    "DATA_HOME_DIR = HOMEPATH + \"data/cifar-10/\"\n",
    "DATA_WORKING = DATA_HOME_DIR + \"sample/\"\n",
    "DATA_WORKING_RESULTS = DATA_WORKING + \"results/\"\n",
    "\n",
    "print (\"DATA_WORKING      :\", DATA_WORKING)\n",
    "print (\"DATA_WORKING_RESULTS:\", DATA_WORKING_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5110)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import load_model \n",
    "import os\n",
    "\n",
    "print(\"----------------\")\n",
    "def set_keras_backend(backend):\n",
    "\n",
    "    if K.backend() != backend:\n",
    "        os.environ['KERAS_BACKEND'] = backend\n",
    "        reload(K)\n",
    "        assert K.backend() == backend\n",
    "\n",
    "set_keras_backend(\"theano\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('os.getcwd:', '/home/ubuntu/fastai')\n"
     ]
    }
   ],
   "source": [
    "os.chdir(HOMEPATH)\n",
    "print (\"os.getcwd:\", os.getcwd())\n",
    "# Rather than importing everything manually, we'll make things easy\n",
    "#   and load them all in utils.py, and just import them from there.\n",
    "%matplotlib inline\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from utils import plots, get_batches, plot_confusion_matrix, get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('os.getcwd:', '/home/ubuntu/fastai')\n"
     ]
    }
   ],
   "source": [
    "os.chdir(HOMEPATH)\n",
    "print (\"os.getcwd:\", os.getcwd())\n",
    "%matplotlib inline\n",
    "from __future__ import division,print_function\n",
    "import os, json\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from random import shuffle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "from matplotlib import pyplot as plt\n",
    "import cPickle as pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import random, permutation\n",
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from vgg16 import Vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = HOMEPATH + \"data/dogscats/sample/\"\n",
    "path = DATA_HOME_DIR \n",
    "#path = DATA_HOME_DIR + \"sample/\"\n",
    "train_path = path + 'train/'\n",
    "test_path = path + 'test/'\n",
    "testUnknown_path = path + 'test/unknown/'\n",
    "valid_path = path + 'valid/'\n",
    "model_path = path + 'models/'\n",
    "sample_path = path + 'sample/'\n",
    "sampleTrain_path = path + 'sample/train/'\n",
    "sampleTest_path = path + 'sample/test/'\n",
    "sampleValid_path = path + 'sample/valid/'\n",
    "sampleResults_path = path + 'sample/results/'\n",
    "sampleTestUnknown_path = path + 'sample/test/unknown/'\n",
    "\n",
    "categories = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dirFileList(dir_path):\n",
    "    return [name for name in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, name))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of files in /home/ubuntu/fastai/data/cifar-10/train/airplane : 3200\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/train/automobile : 3200\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/train/bird : 3200\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/train/cat : 3200\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/train/deer : 3200\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/train/dog : 3200\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/train/frog : 3200\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/train/horse : 3200\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/train/ship : 3200\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/train/truck : 3200\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/valid/airplane : 800\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/valid/automobile : 800\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/valid/bird : 800\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/valid/cat : 800\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/valid/deer : 800\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/valid/dog : 800\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/valid/frog : 800\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/valid/horse : 800\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/valid/ship : 800\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/valid/truck : 800\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/sample/train/airplane : 800\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/sample/train/automobile : 800\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/sample/train/bird : 800\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/sample/train/cat : 800\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/sample/train/deer : 800\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/sample/train/dog : 800\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/sample/train/frog : 800\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/sample/train/horse : 800\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/sample/train/ship : 800\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/sample/train/truck : 800\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/sample/valid/airplane : 200\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/sample/valid/automobile : 200\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/sample/valid/bird : 200\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/sample/valid/cat : 200\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/sample/valid/deer : 200\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/sample/valid/dog : 200\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/sample/valid/frog : 200\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/sample/valid/horse : 200\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/sample/valid/ship : 200\n",
      "# of files in /home/ubuntu/fastai/data/cifar-10/sample/valid/truck : 200\n"
     ]
    }
   ],
   "source": [
    "dirList = [train_path, valid_path, sampleTrain_path, sampleValid_path]\n",
    "\n",
    "for dir_path in dirList:\n",
    "    for category in categories:\n",
    "        print (\"# of files in\", dir_path+category, \":\", len(dirFileList(dir_path+category)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(vgg): <type 'instance'>\n",
      "type(model): <class 'keras.models.Sequential'>\n"
     ]
    }
   ],
   "source": [
    "vgg = Vgg16()\n",
    "model = vgg.model\n",
    "print (\"type(vgg):\", type(vgg))\n",
    "print (\"type(model):\", type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showLayersInfo(model):\n",
    "    print (\"Number of layers : \", len(model.layers))\n",
    "    for layer in model.layers:\n",
    "        print (type(layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers :  38\n",
      "<class 'keras.layers.core.Lambda'>\n",
      "<class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "<class 'keras.layers.convolutional.Convolution2D'>\n",
      "<class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "<class 'keras.layers.convolutional.Convolution2D'>\n",
      "<class 'keras.layers.pooling.MaxPooling2D'>\n",
      "<class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "<class 'keras.layers.convolutional.Convolution2D'>\n",
      "<class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "<class 'keras.layers.convolutional.Convolution2D'>\n",
      "<class 'keras.layers.pooling.MaxPooling2D'>\n",
      "<class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "<class 'keras.layers.convolutional.Convolution2D'>\n",
      "<class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "<class 'keras.layers.convolutional.Convolution2D'>\n",
      "<class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "<class 'keras.layers.convolutional.Convolution2D'>\n",
      "<class 'keras.layers.pooling.MaxPooling2D'>\n",
      "<class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "<class 'keras.layers.convolutional.Convolution2D'>\n",
      "<class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "<class 'keras.layers.convolutional.Convolution2D'>\n",
      "<class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "<class 'keras.layers.convolutional.Convolution2D'>\n",
      "<class 'keras.layers.pooling.MaxPooling2D'>\n",
      "<class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "<class 'keras.layers.convolutional.Convolution2D'>\n",
      "<class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "<class 'keras.layers.convolutional.Convolution2D'>\n",
      "<class 'keras.layers.convolutional.ZeroPadding2D'>\n",
      "<class 'keras.layers.convolutional.Convolution2D'>\n",
      "<class 'keras.layers.pooling.MaxPooling2D'>\n",
      "<class 'keras.layers.core.Flatten'>\n",
      "<class 'keras.layers.core.Dense'>\n",
      "<class 'keras.layers.core.Dropout'>\n",
      "<class 'keras.layers.core.Dense'>\n",
      "<class 'keras.layers.core.Dropout'>\n",
      "<class 'keras.layers.core.Dense'>\n"
     ]
    }
   ],
   "source": [
    "showLayersInfo(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 3, 224, 224)   0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_1 (ZeroPadding2D)  (None, 3, 226, 226)   0           lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 64, 224, 224)  1792        zeropadding2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_2 (ZeroPadding2D)  (None, 64, 226, 226)  0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 64, 224, 224)  36928       zeropadding2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 64, 112, 112)  0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_3 (ZeroPadding2D)  (None, 64, 114, 114)  0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 128, 112, 112) 73856       zeropadding2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_4 (ZeroPadding2D)  (None, 128, 114, 114) 0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 128, 112, 112) 147584      zeropadding2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 128, 56, 56)   0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_5 (ZeroPadding2D)  (None, 128, 58, 58)   0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 256, 56, 56)   295168      zeropadding2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_6 (ZeroPadding2D)  (None, 256, 58, 58)   0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 256, 56, 56)   590080      zeropadding2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_7 (ZeroPadding2D)  (None, 256, 58, 58)   0           convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_7 (Convolution2D)  (None, 256, 56, 56)   590080      zeropadding2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 256, 28, 28)   0           convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_8 (ZeroPadding2D)  (None, 256, 30, 30)   0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 512, 28, 28)   1180160     zeropadding2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_9 (ZeroPadding2D)  (None, 512, 30, 30)   0           convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)  (None, 512, 28, 28)   2359808     zeropadding2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_10 (ZeroPadding2D) (None, 512, 30, 30)   0           convolution2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_10 (Convolution2D) (None, 512, 28, 28)   2359808     zeropadding2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 512, 14, 14)   0           convolution2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_11 (ZeroPadding2D) (None, 512, 16, 16)   0           maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_11 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_12 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_13 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_13 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 512, 7, 7)     0           convolution2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 25088)         0           maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 4096)          102764544   flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 4096)          0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 4096)          16781312    dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 4096)          0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 1000)          4097000     dropout_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_WORKING: /home/ubuntu/fastai/data/cifar-10/sample/\n"
     ]
    }
   ],
   "source": [
    "print(\"DATA_WORKING:\", DATA_WORKING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startTime: 2017-12-10 02:17:15.862649\n",
      "Found 2000 images belonging to 10 classes.\n",
      "val_batches: Time elapsed (hh:mm:ss.ms) 0:00:00.045120\n",
      "\n",
      "\n",
      "startTime: 2017-12-10 02:17:15.908186\n",
      "Found 8000 images belonging to 10 classes.\n",
      "batches : Time elapsed (hh:mm:ss.ms) 0:00:00.168023\n"
     ]
    }
   ],
   "source": [
    "# Use batch size of 1 since we're just doing preprocessing on the CPU\n",
    "startTime= datetime.now()\n",
    "print (\"startTime:\", startTime)\n",
    "val_batches = get_batches(DATA_WORKING+'valid/', shuffle=False, batch_size=1)\n",
    "timeElapsed=datetime.now()-startTime\n",
    "print('val_batches: Time elapsed (hh:mm:ss.ms) {}'.format(timeElapsed))\n",
    "\n",
    "print (\"\\n\")\n",
    "\n",
    "startTime= datetime.now()\n",
    "print (\"startTime:\", startTime)\n",
    "batches     = get_batches(DATA_WORKING+'train/', shuffle=False, batch_size=1)\n",
    "timeElapsed=datetime.now()-startTime\n",
    "print('batches : Time elapsed (hh:mm:ss.ms) {}'.format(timeElapsed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_batches: <class 'keras.preprocessing.image.DirectoryIterator'>\n",
      "batches: <class 'keras.preprocessing.image.DirectoryIterator'>\n"
     ]
    }
   ],
   "source": [
    "print (\"val_batches:\", type(val_batches))\n",
    "print (\"batches:\", type(batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bcolz\n",
    "def save_array(fname, arr): c=bcolz.carray(arr, rootdir=fname, mode='w'); c.flush()\n",
    "def load_array(fname):\n",
    "    print (\"load_array:fname:\", fname)\n",
    "    return bcolz.open(fname)[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_WORKING: /home/ubuntu/fastai/data/cifar-10/sample/\n",
      "startTime: 2017-12-10 02:17:23.981561\n",
      "Found 2000 images belonging to 10 classes.\n",
      "val_data: <type 'numpy.ndarray'> (2000, 3, 224, 224)\n",
      "val_data:Time elapsed (hh:mm:ss.ms) 0:00:16.216743\n"
     ]
    }
   ],
   "source": [
    "print (\"DATA_WORKING:\", DATA_WORKING)\n",
    "#utils.get_data\n",
    "startTime= datetime.now()\n",
    "print (\"startTime:\", startTime)\n",
    "\n",
    "val_data = get_data(DATA_WORKING+'valid')\n",
    "\n",
    "print (\"val_data:\", type(val_data), val_data.shape)\n",
    "\n",
    "timeElapsed=datetime.now()-startTime\n",
    "print('val_data:Time elapsed (hh:mm:ss.ms) {}'.format(timeElapsed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_WORKING: /home/ubuntu/fastai/data/cifar-10/sample/\n",
      "startTime: 2017-12-10 02:17:40.207370\n",
      "Found 8000 images belonging to 10 classes.\n",
      "trn_data: <type 'numpy.ndarray'> (8000, 3, 224, 224)\n",
      "Time elapsed (hh:mm:ss.ms) 0:01:04.800115\n"
     ]
    }
   ],
   "source": [
    "print (\"DATA_WORKING:\", DATA_WORKING)\n",
    "startTime= datetime.now()\n",
    "print (\"startTime:\", startTime)\n",
    "\n",
    "trn_data = get_data(DATA_WORKING+'train')\n",
    "print (\"trn_data:\", type(trn_data), trn_data.shape)\n",
    "\n",
    "timeElapsed=datetime.now()-startTime\n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(timeElapsed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_WORKING_RESULTS: /home/ubuntu/fastai/data/cifar-10/sample/results/\n"
     ]
    }
   ],
   "source": [
    "print (\"DATA_WORKING_RESULTS:\", DATA_WORKING_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils.save_array uses bcolz. very small filesize generated.\n",
    "save_array(DATA_WORKING_RESULTS+'train_data.bc', trn_data)\n",
    "save_array(DATA_WORKING_RESULTS+'valid_data.bc', val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"DATA_WORKING_RESULTS:\", DATA_WORKING_RESULTS)\n",
    "print (DATA_WORKING_RESULTS+'train_data.bc')\n",
    "trn_data = load_array(DATA_WORKING_RESULTS+'train_data.bc')\n",
    "val_data = load_array(DATA_WORKING_RESULTS+'valid_data.bc')\n",
    "print (\"trn_data:\", type(trn_data), trn_data.shape)#should return trn_data: <type 'numpy.ndarray'> (8000, 3, 224, 224)\n",
    "print (\"val_data:\", type(val_data), val_data.shape)#should return val_data: <type 'numpy.ndarray'> (2000, 3, 224, 224)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keras returns *classes* as a single column, so we convert to one hot encoding\n",
    "def onehot(x): \n",
    "    return np.array(OneHotEncoder().fit_transform(x.reshape(-1,1)).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_classes: <type 'numpy.ndarray'> (2000,)\n",
      "val_classes[0:10]: [0 0 0 0 0 0 0 0 0 0]\n",
      "trn_classes: <type 'numpy.ndarray'> (8000,)\n",
      "trn_classes[0:10]: [0 0 0 0 0 0 0 0 0 0]\n",
      "after onehot conversion.\n",
      "val_labels: [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "trn_labels: [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "val_classes = val_batches.classes\n",
    "trn_classes = batches.classes\n",
    "print (\"val_classes:\", type(val_classes), val_classes.shape)\n",
    "print(\"val_classes[0:10]:\", val_classes[0:10])\n",
    "print (\"trn_classes:\", type(trn_classes), trn_classes.shape)\n",
    "print(\"trn_classes[0:10]:\", trn_classes[0:10])\n",
    "val_labels = onehot(val_classes)\n",
    "trn_labels = onehot(trn_classes)\n",
    "print (\"after onehot conversion.\")\n",
    "print (\"val_labels:\", val_labels[0])\n",
    "print (\"trn_labels:\", trn_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "startTime: 2017-12-10 02:18:46.871680\n",
      "Time elpased (hh:mm:ss.ms) 0:03:25.383038\n"
     ]
    }
   ],
   "source": [
    "print (\"start\")\n",
    "startTime= datetime.now()\n",
    "print (\"startTime:\", startTime)\n",
    "\n",
    "trn_features = model.predict(trn_data, batch_size=batch_size)\n",
    "\n",
    "timeElapsed=datetime.now()-startTime\n",
    "print('Time elpased (hh:mm:ss.ms) {}'.format(timeElapsed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startTime: 2017-12-10 02:22:12.262820\n",
      "Time elpased (hh:mm:ss.ms) 0:00:50.662152\n"
     ]
    }
   ],
   "source": [
    "startTime= datetime.now()\n",
    "print (\"startTime:\", startTime)\n",
    "\n",
    "val_features = model.predict(val_data, batch_size=batch_size)\n",
    "\n",
    "timeElapsed=datetime.now()-startTime\n",
    "print('Time elpased (hh:mm:ss.ms) {}'.format(timeElapsed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn_features: (8000, 1000)\n",
      "val_features: (2000, 1000)\n"
     ]
    }
   ],
   "source": [
    "print (\"trn_features:\", trn_features.shape)\n",
    "print (\"val_features:\", val_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_WORKING_RESULTS: /home/ubuntu/fastai/data/cifar-10/sample/results/\n"
     ]
    }
   ],
   "source": [
    "print (\"DATA_WORKING_RESULTS:\",DATA_WORKING_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_array(DATA_WORKING_RESULTS+'train_lastlayer_features.bc', trn_features)\n",
    "#save_array(DATA_WORKING_RESULTS+'valid_lastlayer_features.bc', val_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trn_features = load_array(DATA_WORKING_RESULTS+'train_lastlayer_features.bc')\n",
    "#val_features = load_array(DATA_WORKING_RESULTS+'valid_lastlayer_features.bc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn_features: <type 'numpy.ndarray'> (8000, 1000)\n",
      "val_features: <type 'numpy.ndarray'> (2000, 1000)\n"
     ]
    }
   ],
   "source": [
    "print (\"trn_features:\", type(trn_features), trn_features.shape)\n",
    "print (\"val_features:\", type(val_features), val_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startTime: 2017-12-10 02:23:03.042408\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:00.010958\n"
     ]
    }
   ],
   "source": [
    "# 1000 inputs, since trn_features.shape[1]=1000, and 10 outputs, for # of categories\n",
    "startTime= datetime.now()\n",
    "print (\"startTime:\", startTime)\n",
    "\n",
    "\n",
    "lm = Sequential([ Dense(10, activation='softmax', input_shape=(1000,)) ])\n",
    "lm.compile(optimizer=RMSprop(lr=0.1), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "timeElapsed=datetime.now()-startTime\n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(timeElapsed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lm: <class 'keras.models.Sequential'>\n"
     ]
    }
   ],
   "source": [
    "print (\"lm:\", type(lm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'> 10\n"
     ]
    }
   ],
   "source": [
    "print (type(categories), len(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startTime: 2017-12-10 02:23:03.083982\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/3\n",
      "8000/8000 [==============================] - 0s - loss: 1.8685 - acc: 0.3334 - val_loss: 1.7090 - val_acc: 0.4070\n",
      "Epoch 2/3\n",
      "8000/8000 [==============================] - 0s - loss: 1.6563 - acc: 0.4254 - val_loss: 1.6283 - val_acc: 0.4305\n",
      "Epoch 3/3\n",
      "8000/8000 [==============================] - 0s - loss: 1.5845 - acc: 0.4511 - val_loss: 1.5909 - val_acc: 0.4355\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:01.630605\n"
     ]
    }
   ],
   "source": [
    "startTime= datetime.now()\n",
    "print (\"startTime:\", startTime)\n",
    "\n",
    "lm.fit(trn_features, trn_labels, nb_epoch=3, batch_size=batch_size, \n",
    "       validation_data=(val_features, val_labels))\n",
    "\n",
    "timeElapsed=datetime.now()-startTime\n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(timeElapsed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.models.Sequential'>\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_4 (Dense)                  (None, 10)            10010       dense_input_1[0][0]              \n",
      "====================================================================================================\n",
      "Total params: 10,010\n",
      "Trainable params: 10,010\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print (type(lm))\n",
    "print (lm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startTime: 2017-12-10 02:23:04.813410\n",
      "  64/2000 [..............................] - ETA: 0sTime elapsed (hh:mm:ss.ms) 0:00:00.041477\n"
     ]
    }
   ],
   "source": [
    "startTime= datetime.now()\n",
    "print (\"startTime:\", startTime)\n",
    "\n",
    "preds = lm.predict_classes(val_features, batch_size=batch_size)\n",
    "\n",
    "timeElapsed=datetime.now()-startTime\n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(timeElapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'> (2000,)\n",
      "preds[0:10]: [0 0 8 8 9 2 8 9 0 2]\n"
     ]
    }
   ],
   "source": [
    "print (type(preds), preds.shape)\n",
    "print (\"preds[0:10]:\", preds[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startTime: 2017-12-10 02:23:04.871764\n",
      "  64/2000 [..............................] - ETA: 0sTime elapsed (hh:mm:ss.ms) 0:00:00.015369\n",
      "probs: <type 'numpy.ndarray'> (2000, 10)\n",
      "[  5.3097e-01   7.3832e-02   5.6984e-02   5.8013e-05   6.1580e-05   4.6224e-06   1.2243e-06\n",
      "   3.2969e-03   2.3928e-01   9.5514e-02]\n",
      "['0.5310', '0.0738', '0.0570', '0.0001', '0.0001', '0.0000', '0.0000', '0.0033', '0.2393', '0.0955']\n"
     ]
    }
   ],
   "source": [
    "startTime= datetime.now()\n",
    "print (\"startTime:\", startTime)\n",
    "\n",
    "#probabilities of each category results in numpy array with column for each category.\n",
    "probs = lm.predict_proba(val_features, batch_size=batch_size)#[:,0]\n",
    "\n",
    "timeElapsed=datetime.now()-startTime\n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(timeElapsed))\n",
    "\n",
    "print (\"probs:\", type(probs), probs.shape)\n",
    "print (probs[0,])\n",
    "print ( [\"%.4f\" % v for v in probs[0,]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filenames: <type 'list'> 2000\n",
      "['airplane/28450.png', 'airplane/35856.png', 'airplane/26724.png', 'airplane/16514.png', 'airplane/36622.png', 'airplane/12430.png', 'airplane/14586.png', 'airplane/21106.png', 'airplane/29040.png', 'airplane/43910.png']\n"
     ]
    }
   ],
   "source": [
    "filenames = val_batches.filenames\n",
    "print (\"filenames:\", type(filenames), len(filenames))\n",
    "print (filenames[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of images to view for each visualization task\n",
    "n_view = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classesFromFilenames(filenames):\n",
    "    #returns text versions of categories from filenames.\n",
    "    #requires filenames in format of 'category-text-form/123456.png'\n",
    "    #strips out the category-text-form prior to '/'\n",
    "    classes = []\n",
    "    #print (\"classesFromFilenames:idx:\", idx)\n",
    "    for i in range(0, len(filenames)):\n",
    "        pos = filenames[i].find('/')\n",
    "        #print (\"pos:\", pos, filenames[i][0:pos])\n",
    "        classes.append(filenames[i][0:pos])\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classesFromPreds(preds, categories):\n",
    "    #returns text versions of categories\n",
    "    categs = []\n",
    "    for pred in preds:\n",
    "        #print(\"pred:\", pred, categories[pred])\n",
    "        categs.append(categories[pred])\n",
    "    return categs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots_idx(path, idx, titles=None):\n",
    "    #titles = numpy array idx rows x 10 columns, need to select highest prob from each row.\n",
    "    maxProb = []\n",
    "    for i in range(0, titles.shape[0]):\n",
    "        #print (titles[i,], type(titles[i,]))\n",
    "        #print (np.argmax(titles[i,]))\n",
    "        maxProb.append(titles[i,np.argmax(titles[i,])])\n",
    "    plots([image.load_img(path + filenames[i]) for i in idx], titles=maxProb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categsFromFileNames = classesFromFilenames(filenames)\n",
    "print(\"categsFromFileNames:\", len(categsFromFileNames), categsFromFileNames[0:4])\n",
    "categsFromPreds = classesFromPreds(preds, categories)\n",
    "print(\"categsFromPreds:\", len(categsFromPreds), categsFromPreds[0:4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plotSamples(matchIndex):\n",
    "    #numpy.random.permutation\n",
    "    idx = permutation(matchIndex)[:n_view]\n",
    "    print (\"idx:\", idx)\n",
    "    for i in idx:\n",
    "        print(filenames[i])\n",
    "\n",
    "    #print (classesFromFilenames(idx, filenames))\n",
    "    #print (\"probs[idx].shape:\", probs[idx].shape)\n",
    "    plots_idx(DATA_WORKING+'valid/', idx, probs[idx])\n",
    "    #print (\"idx:\", idx)\n",
    "    print (\"actual from filenames:\", [categsFromFileNames[i] for i in idx])\n",
    "    print (\"predicted            :\",     [categsFromPreds[i] for i in idx])\n",
    "    #print (\"probs[idx[0],]:\", probs[idx[0],])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select correctly predicted.\n",
    "matchIndex = []\n",
    "for i in range(0,len(categsFromFileNames)):\n",
    "    if categsFromFileNames[i]==categsFromPreds[i]:\n",
    "        matchIndex.append(i)\n",
    "print (\"# of correctly predicted : matchIndex:\", len(matchIndex))\n",
    "plotSamples(matchIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#select incorrectly predicted.\n",
    "matchIndex = []\n",
    "for i in range(0,len(categsFromFileNames)):\n",
    "    if categsFromFileNames[i]!=categsFromPreds[i]:\n",
    "        matchIndex.append(i)\n",
    "print (\"# of incorrectly predicted : matchIndex:\", len(matchIndex))\n",
    "plotSamples(matchIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(val_classes, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"type(val_batches.class_indices):\", type(val_batches.class_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(12,12)) #does not affect size, method is inside utils\n",
    "\n",
    "plot_confusion_matrix(cm, val_batches.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"before pop, # of layers:\", len(model.layers))\n",
    "if len(model.layers)==38:\n",
    "    print (\"# of layers == 38., poping top layer.\")\n",
    "    model.pop()\n",
    "else:\n",
    "    print (\"# of layers not == 38.\")\n",
    "print (\"after pop, # of layers:\", len(model.layers))\n",
    "for layer in model.layers: layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (type(vgg.model))\n",
    "#not really useful, here for reference only\n",
    "#for layer in model.layers:\n",
    "#    print(layer.name, layer.inbound_nodes, layer.outbound_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10, activation='softmax'))#NB: Dense requires 10 because 10 categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"after adding dense layer, # of layers:\", len(model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen=image.ImageDataGenerator()\n",
    "print (\"gen:\", type(gen))\n",
    "batches = gen.flow(trn_data, trn_labels, batch_size=batch_size, shuffle=True)\n",
    "#https://keras.io/preprocessing/image/\n",
    "#flow(x, y): Takes numpy data & label arrays, \n",
    "#and generates batches of augmented/normalized data. \n",
    "#Yields batches indefinitely, in an infinite loop.\n",
    "\n",
    "val_batches = gen.flow(val_data, val_labels, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print (\"batches:\", type(batches))\n",
    "print (\"val_batches:\", type(val_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, batches, val_batches, nb_epoch=1):\n",
    "    model.fit_generator(batches, \n",
    "                        samples_per_epoch=batches.n, \n",
    "                        nb_epoch=nb_epoch, \n",
    "                        validation_data=val_batches, \n",
    "                        nb_val_samples=val_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = RMSprop(lr=0.1)\n",
    "#https://keras.io/optimizers/#rmsprop\n",
    "#This optimizer is usually a good choice for recurrent neural networks.\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime= datetime.now()\n",
    "fit_model(model, batches, val_batches, nb_epoch=2)\n",
    "timeElapsed=datetime.now()-startTime\n",
    "print('Time elpased (hh:mm:ss.ms) {}'.format(timeElapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"DATA_WORKING_RESULTS:\", DATA_WORKING_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(DATA_WORKING_RESULTS+'finetune1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights(DATA_WORKING_RESULTS+'finetune1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(val_data, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"type(model):\", type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict_classes(val_data, batch_size=batch_size)\n",
    "probs = model.predict_proba(val_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"preds:\", preds.shape)\n",
    "print(\"probs:\", probs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs[:8,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(val_classes, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"type(val_batches):\", type(val_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#recall - val_batches was generated from loading files. possibly need to initialize again?\n",
    "#val_batches = get_batches(DATA_WORKING+'valid/', shuffle=False, batch_size=1)\n",
    "#plot_confusion_matrix(cm, val_batches.class_indices)\n",
    "#AttributeError: 'NumpyArrayIterator' object has no attribute 'class_indices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    print (type(layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = model.layers\n",
    "# Get the index of the first dense layer...\n",
    "first_dense_idx = [index for index,layer in enumerate(layers) if type(layer) is Dense][0]\n",
    "print (type(first_dense_idx), first_dense_idx)\n",
    "# ...and set this and all subsequent layers to trainable\n",
    "for layer in layers[first_dense_idx:]: \n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(K)\n",
    "#recall from above: from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_value(opt.lr, 0.01)\n",
    "#https://keras.io/backend/\n",
    "#keras.backend.set_value(x, value)\n",
    "#https://www.tensorflow.org/api_docs/python/tf/keras/backend/set_value\n",
    "\n",
    "    \n",
    "fit_model(model, batches, val_batches, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(DATA_WORKING_RESULTS+'finetune2_.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in layers[12:]: layer.trainable=True\n",
    "K.set_value(opt.lr, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_model(model, batches, val_batches, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(DATA_WORKING_RESULTS+'finetune3_.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model #move this to top when run complete.\n",
    "model.save(DATA_WORKING_RESULTS+'CIFAR-10_part2_final_model_.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_object(obj, filename):\n",
    "    filename = DATA_WORKING_RESULTS+filename\n",
    "    with open(filename, 'wb') as output:\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "    print (\"method save_object loaded with DATA_WORKING_RESULTS=\", DATA_WORKING_RESULTS)\n",
    "# sample usage\n",
    "#save_object(company1, 'company1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object(model, 'CIFAR-10_part2_final_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_model = pickle.load( open( DATA_WORKING_RESULTS+'CIFAR-10_part2_final_model.pkl', \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(pickle_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_features = load_array(DATA_WORKING_RESULTS+'valid_lastlayer_features.bc')\n",
    "print (\"val_features:\", type(val_features), val_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime= datetime.now()\n",
    "print (\"startTime:\", startTime)\n",
    "\n",
    "preds = model.predict_classes(val_features, batch_size=batch_size)\n",
    "\n",
    "timeElapsed=datetime.now()-startTime\n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(timeElapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
