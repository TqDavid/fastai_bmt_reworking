{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drawn from https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Small LSTM Network to Generate Text for Alice in Wonderland\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from datetime import datetime\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"http://www.gutenberg.org/cache/epub/11/pg11.txt\"\n",
    "#scp -i /c/blah/.ssh/blah.pem /d/blah/alice_in_wonderland_11-0.txt ubuntu@blah:~/blah/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ascii text and covert to lowercase\n",
    "filename = \"alice_in_wonderland_11-0.txt\"\n",
    "raw_text = open(filename).read()\n",
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'str'> 173595\n"
     ]
    }
   ],
   "source": [
    "print type(raw_text), len(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed (hh:mm:ss.ms) 0:00:00.011232\n"
     ]
    }
   ],
   "source": [
    "#strip non alpha characters from source text.\n",
    "regex = re.compile('[^a-zA-Z]')\n",
    "\n",
    "startTime= datetime.now()\n",
    "raw_text = regex.sub('', raw_text)\n",
    "timeElapsed=datetime.now()-startTime\n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(timeElapsed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  123011\n",
      "Total Vocab:  26\n",
      "chars:\n",
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "# create mapping of unique chars to integers\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "# summarize the loaded data\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print \"Total Characters: \", n_chars\n",
    "print \"Total Vocab: \", n_vocab\n",
    "print \"chars:\\n\", chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  123011\n",
      "Total Vocab:  26\n"
     ]
    }
   ],
   "source": [
    "# create mapping of unique chars to integers\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "# summarize the loaded data\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print \"Total Characters: \", n_chars\n",
    "print \"Total Vocab: \", n_vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  122911\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print \"Total Patterns: \", n_patterns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122911, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'> (122911, 26)\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)\n",
    "print type(y), y.shape\n",
    "print y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lstm_1 (LSTM)                    (None, 100, 256)      264192      lstm_input_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 100, 256)      0           lstm_1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                    (None, 256)           525312      dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 256)           0           lstm_2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 26)            6682        dropout_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 796,186\n",
      "Trainable params: 796,186\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "print model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}-improvedA.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "#https://keras.io/callbacks/\n",
    "#Save the model after every epoch.\n",
    "#NB: this appears to be saving a file for every epoch, huge disk space hog.\n",
    "'''\n",
    "Arguments\n",
    "\n",
    "filepath: string, path to save the model file.\n",
    "\n",
    "monitor: quantity to monitor.\n",
    "\n",
    "verbose: verbosity mode, 0 or 1.\n",
    "\n",
    "save_best_only: if save_best_only=True, the latest best model according to the quantity monitored will not be overwritten.\n",
    "\n",
    "mode: one of {auto, min, max}. If save_best_only=True, the decision to overwrite the current save file is made based on \n",
    "either the maximization or the minimization of the monitored quantity. \n",
    "For val_acc, this should be max, for val_loss this should be min, etc. \n",
    "In auto mode, the direction is automatically inferred from the name of the monitored quantity.\n",
    "\n",
    "save_weights_only: if True, then only the model's weights will be saved (model.save_weights(filepath)), \n",
    "else the full model is saved (model.save(filepath)).\n",
    "\n",
    "period: Interval (number of epochs) between checkpoints.\n",
    "'''\n",
    "\n",
    "callbacks_list = [checkpoint]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('started at ', datetime.datetime(2017, 11, 22, 0, 25, 33, 447631))\n",
      "Epoch 1/50\n",
      "122880/122911 [============================>.] - ETA: 0s - loss: 2.8814Epoch 00000: loss improved from inf to 2.88139, saving model to weights-improvement-00-2.8814-improvedA.hdf5\n",
      "122911/122911 [==============================] - 512s - loss: 2.8814   \n",
      "Epoch 2/50\n",
      "122880/122911 [============================>.] - ETA: 0s - loss: 2.7939Epoch 00001: loss improved from 2.88139 to 2.79385, saving model to weights-improvement-01-2.7938-improvedA.hdf5\n",
      "122911/122911 [==============================] - 511s - loss: 2.7938   \n",
      "Epoch 3/50\n",
      "122880/122911 [============================>.] - ETA: 0s - loss: 2.6485Epoch 00002: loss improved from 2.79385 to 2.64847, saving model to weights-improvement-02-2.6485-improvedA.hdf5\n",
      "122911/122911 [==============================] - 508s - loss: 2.6485   \n",
      "Epoch 4/50\n",
      "122880/122911 [============================>.] - ETA: 0s - loss: 2.5028Epoch 00003: loss improved from 2.64847 to 2.50274, saving model to weights-improvement-03-2.5027-improvedA.hdf5\n",
      "122911/122911 [==============================] - 509s - loss: 2.5027   \n",
      "Epoch 5/50\n",
      "122880/122911 [============================>.] - ETA: 0s - loss: 2.3876Epoch 00004: loss improved from 2.50274 to 2.38757, saving model to weights-improvement-04-2.3876-improvedA.hdf5\n",
      "122911/122911 [==============================] - 509s - loss: 2.3876   \n",
      "Epoch 6/50\n",
      "122880/122911 [============================>.] - ETA: 0s - loss: 2.2983Epoch 00005: loss improved from 2.38757 to 2.29820, saving model to weights-improvement-05-2.2982-improvedA.hdf5\n",
      "122911/122911 [==============================] - 506s - loss: 2.2982   \n",
      "Epoch 7/50\n",
      "122880/122911 [============================>.] - ETA: 0s - loss: 2.2180Epoch 00006: loss improved from 2.29820 to 2.21799, saving model to weights-improvement-06-2.2180-improvedA.hdf5\n",
      "122911/122911 [==============================] - 507s - loss: 2.2180   \n",
      "Epoch 8/50\n",
      "122880/122911 [============================>.] - ETA: 0s - loss: 2.1516Epoch 00007: loss improved from 2.21799 to 2.15168, saving model to weights-improvement-07-2.1517-improvedA.hdf5\n",
      "122911/122911 [==============================] - 505s - loss: 2.1517   \n",
      "Epoch 9/50\n",
      "122880/122911 [============================>.] - ETA: 0s - loss: 2.0922Epoch 00008: loss improved from 2.15168 to 2.09214, saving model to weights-improvement-08-2.0921-improvedA.hdf5\n",
      "122911/122911 [==============================] - 504s - loss: 2.0921   \n",
      "Epoch 10/50\n",
      "122880/122911 [============================>.] - ETA: 0s - loss: 2.0380Epoch 00009: loss improved from 2.09214 to 2.03802, saving model to weights-improvement-09-2.0380-improvedA.hdf5\n",
      "122911/122911 [==============================] - 504s - loss: 2.0380   \n",
      "Epoch 11/50\n",
      "122880/122911 [============================>.] - ETA: 0s - loss: 1.9897Epoch 00010: loss improved from 2.03802 to 1.98968, saving model to weights-improvement-10-1.9897-improvedA.hdf5\n",
      "122911/122911 [==============================] - 504s - loss: 1.9897   \n",
      "Epoch 12/50\n",
      "122880/122911 [============================>.] - ETA: 0s - loss: 1.9502Epoch 00011: loss improved from 1.98968 to 1.95018, saving model to weights-improvement-11-1.9502-improvedA.hdf5\n",
      "122911/122911 [==============================] - 503s - loss: 1.9502   \n",
      "Epoch 13/50\n",
      "122880/122911 [============================>.] - ETA: 0s - loss: 1.9106Epoch 00012: loss improved from 1.95018 to 1.91081, saving model to weights-improvement-12-1.9108-improvedA.hdf5\n",
      "122911/122911 [==============================] - 506s - loss: 1.9108   \n",
      "Epoch 14/50\n",
      "122880/122911 [============================>.] - ETA: 0s - loss: 1.8723Epoch 00013: loss improved from 1.91081 to 1.87223, saving model to weights-improvement-13-1.8722-improvedA.hdf5\n",
      "122911/122911 [==============================] - 507s - loss: 1.8722   \n",
      "Epoch 15/50\n",
      " 95040/122911 [======================>.......] - ETA: 114s - loss: 1.8349"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "startTime= datetime.now()\n",
    "print (\"started at \", startTime)\n",
    "model.fit(X, y, nb_epoch=50, batch_size=64, callbacks=callbacks_list)\n",
    "timeElapsed=datetime.now()-startTime\n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(timeElapsed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
